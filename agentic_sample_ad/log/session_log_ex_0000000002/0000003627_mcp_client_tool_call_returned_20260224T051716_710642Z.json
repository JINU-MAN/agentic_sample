{
  "ts": "2026-02-24T05:17:16.710642+00:00",
  "level": "INFO",
  "component": "mcp_client",
  "action": "tool_call_returned",
  "direction": "inbound",
  "details": {
    "server_script_path": "C:\\agentic_sample_api\\agentic_sample_ad\\mcp_local\\paper_server.py",
    "tool_name": "get_paper_head",
    "result": {
      "content": [
        {
          "type": "text",
          "text": "{\n  \"ok\": true,\n  \"path\": \"C:\\\\agentic_sample_api\\\\agentic_sample_ad\\\\db\\\\paper\\\\Security Analysis of Agentic Communication Protocols.pdf\",\n  \"filename\": \"Security Analysis of Agentic Communication Protocols.pdf\",\n  \"char_count\": 9095,\n  \"head_full_char_count\": 9095,\n  \"head_max_pages\": 4,\n  \"truncated\": false,\n  \"content\": \"Security Analysis of Agentic AI\\nCommunication Protocols: A Comparative\\nEvaluation\\nYedidel Louck\\n , Ariel Stulman\\n , Amit Dvir\\n ∗\\nNovember 7, 2025\\nAbstract\\nMulti-agent systems (MAS) powered by artificial intelligence (AI)\\nare increasingly foundational to complex, distributed workflows. Yet,\\nthe security of their underlying communication protocols remains crit-\\nically under-examined. This paper presents the first empirical, com-\\nparative security analysis of the official CORAL implementation and a\\nhigh-fidelity, SDK-based ACP implementation, benchmarked against\\na literature-based evaluation of A2A. Using a 14 point vulnerability\\ntaxonomy, we systematically assess their defenses across authentica-\\ntion, authorization, integrity, confidentiality, and availability. Our\\nresults reveal a pronounced security dichotomy: CORAL exhibits a\\nrobust architectural design, particularly in its transport-layer message\\nvalidation and session isolation, but suffers from critical implementation-\\nlevel vulnerabilities, including authentication and authorization fail-\\nures at its SSE gateway. Conversely, ACP’s architectural flexibil-\\nity, most notably its optional JWS enforcement, translates into high-\\nimpact integrity and confidentiality flaws. We contextualize these find-\\nings within current industry trends, highlighting that existing proto-\\ncols remain insufficiently secure. As a path forward, we recommend\\na hybrid approach that combines CORAL’s integrated architecture\\nwith ACP’s mandatory per-message integrity guarantees, laying the\\ngroundwork for resilient, next-generation agent communications.\\n∗Yedidel Louck and Amit Dvir are with the Department of Computer and Software\\nEngineering, Ariel Cyber Innovation Center, Ariel University, Israel. Ariel Stulman is\\nwith the Department of Computer Science, Jerusalem College of Technology, Israel\\nyedidel.louck@msmail.ariel.ac.il, amitdv@ariel.ac.il, stulman@jct.ac.il\\n1\\narXiv:2511.03841v1  [cs.CR]  5 Nov 2025 1 Introduction\\nThe emergence of agentic Artificial Intelligence (AI) systems, particularly\\nthose powered by large language models (LLMs), has significantly trans-\\nformed the landscape of software autonomy [1]. These intelligent agents, ca-\\npable of reasoning, planning, delegating, and executing complex workflows,\\nnow form the backbone of applications ranging from supply chain coordi-\\nnation to personalized financial assistance. As the scale and complexity of\\nmulti-agent ecosystems increase, so too do the requirements for secure, in-\\nteroperable communication protocols.\\nCommunication between autonomous agents introduces unique security\\nchallenges. Unlike traditional client-server architectures, agent-based sys-\\ntems must manage peer-to-peer trust, dynamic task delegation, and sensi-\\ntive data sharing across heterogeneous actors. In such environments, the risk\\nof credential leakage, overprivileged access, prompt injection, and unverified\\nexecution grows exponentially [2, 3]. Standard security frameworks such as\\nOAuth 2.0 and TLS, while foundational, do not provide sufficient granular-\\nity or contextual awareness for these interactions, especially in cases where\\nagents dynamically compose tasks involving payments, identity verification,\\nor confidential documents [4, 5].\\nTo address these gaps, several agent communication protocols have been\\ndeveloped, each offering a different perspective on interoperability, trust man-\\nagement, and delegation control [6]. Google’sAgent-to-Agent (A2A)protocol\\n[7] introduces a declarative model for service discovery. TheAgent Commu-\\nnication Protocol (ACP)[8] embraces flexibility with a registry-based model.\\nTheCORAL[9] framework, in contrast, proposes a hybrid architecture inte-\\ngrating on-chain smart contracts for payments with off-chain communication.\\n•Google’sAgent-to-Agent (A2A)protocol [7] introduces a declarative\\nmodel for service discovery.\\n•TheAgent Communication Protocol (ACP)[8] embraces flexibility with\\na registry-based model.\\n•TheCORAL[9] framework, in contrast, proposes a hybrid architec-\\nture integrating on-chain smart contracts for payments with off-chain\\ncommunication.\\nWhile these protocols present promising architectures, their security prop-\\nerties are discussed in the literature but rarely subjected to comparative\\nempirical testing [2]. This study fills this gap by providing a detailed, multi-\\ndimensional security analysis and empirical testing. We establish a 14-point\\n2 vulnerability taxonomy (Section 6), derived from literature and threat mod-\\neling.\\nOur findings reveal a critical ”architecture versus implementation” di-\\nchotomy. We demonstrate that CORAL, while possessing a robust architec-\\nture for integrating payments and securing data integrity via transport-layer\\nvalidation, is critically vulnerable in its current public implementation due\\nto fundamental authentication and authorization failures at its SSE gateway.\\nConversely, our tests confirm that ACP’s architectural flexibility is, in itself,\\na vulnerability, leading to predictable integrity failures and data exfiltra-\\ntion in non-strict configurations. Ultimately, this paper contributes both a\\ncomprehensive security taxonomy and the first empirical benchmark of these\\ncompeting protocols. We conclude (Section 11) not by recommending one\\nprotocol, but by proposing a hybrid model that synthesizes CORAL’s ar-\\nchitectural strengths with the mandatory, granular integrity checks of ACP,\\noffering a concrete path forward for resilient, AI-native communications.\\n2 Background\\nMulti-agent systems (MAS) leveraging artificial intelligence (AI) are increas-\\ningly adopted in domains requiring distributed decision-making, automated\\ncoordination, and collaborative reasoning. In such environments, autonomous\\nagents often represent distinct stakeholders or functional modules, exchang-\\ning structured messages through predefined interaction protocols. Repre-\\nsentative use cases include autonomous orchestration, financial transaction\\nsystems, healthcare diagnostics, supply chain optimization, and cybersecu-\\nrity defense.\\nA robust communication protocol in these contexts must ensure more\\nthan reliable message delivery, it must preserve semantic integrity, context\\ncontinuity, role negotiation, and, critically, security guarantees. Since AI\\nagents frequently process or act upon sensitive data, vulnerabilities in their\\ncommunication layers can compromise entire workflows. Therefore, secure\\nagent protocols must provide protection against adversarial entities, unin-\\ntended leakage, manipulation, and systemic compromise.\\nBelow we summarize the principal categories of threats relevant to com-\\nmunication among AI-driven agents. These categories synthesize findings\\nfrom distributed systems, adversarial AI research, and classical network se-\\ncurity.\\n•Prompt Injection:An adversary may inject malicious instructions\\ninto prompts or message payloads, coercing agents to disclose confiden-\\n3 tial data or alter intended behavior. This class of attacks is extensively\\ndiscussed in recent studies [10, 3].\\n•Data Leakage / Exfiltration:Agents may inadvertently reveal pri-\\nvate or proprietary content during multi-turn exchanges, especially\\nwhen sensitive context persists across dialogue rounds [11].\\n•Data Poisoning:Malicious actors can inject corrupted training or\\ncontextual data, influencing downstream models to behave incorrectly\\nor embed hidden triggers. Data poisoning has been empirically shown\\nto scale across distributed and shared-context environments [12].\\n•Adversarial / Malicious Agents:A compromised or impersonated\\...(truncated)"
        }
      ],
      "structuredContent": {
        "result": {
          "ok": true,
          "path": "C:\\agentic_sample_api\\agentic_sample_ad\\db\\paper\\Security Analysis of Agentic Communication Protocols.pdf",
          "filename": "Security Analysis of Agentic Communication Protocols.pdf",
          "char_count": 9095,
          "head_full_char_count": 9095,
          "head_max_pages": 4,
          "truncated": false,
          "content": "Security Analysis of Agentic AI\nCommunication Protocols: A Comparative\nEvaluation\nYedidel Louck\n , Ariel Stulman\n , Amit Dvir\n ∗\nNovember 7, 2025\nAbstract\nMulti-agent systems (MAS) powered by artificial intelligence (AI)\nare increasingly foundational to complex, distributed workflows. Yet,\nthe security of their underlying communication protocols remains crit-\nically under-examined. This paper presents the first empirical, com-\nparative security analysis of the official CORAL implementation and a\nhigh-fidelity, SDK-based ACP implementation, benchmarked against\na literature-based evaluation of A2A. Using a 14 point vulnerability\ntaxonomy, we systematically assess their defenses across authentica-\ntion, authorization, integrity, confidentiality, and availability. Our\nresults reveal a pronounced security dichotomy: CORAL exhibits a\nrobust architectural design, particularly in its transport-layer message\nvalidation and session isolation, but suffers from critical implementation-\nlevel vulnerabilities, including authentication and authorization fail-\nures at its SSE gateway. Conversely, ACP’s architectural flexibil-\nity, most notably its optional JWS enforcement, translates into high-\nimpact integrity and confidentiality flaws. We contextualize these find-\nings within current industry trends, highlighting that existing proto-\ncols remain insufficiently secure. As a path forward, we recommend\na hybrid approach that combines CORAL’s integrated architecture\nwith ACP’s mandatory per-message integrity guarantees, laying the\ngroundwork for resilient, next-generation agent communications.\n∗Yedidel Louck and Amit Dvir are with the Department of Computer and Software\nEngineering, Ariel Cyber Innovation Center, Ariel University, Israel. Ariel Stulman is\nwith the Department of Computer Science, Jerusalem College of Technology, Israel\nyedidel.louck@msmail.ariel.ac.il, amitdv@ariel.ac.il, stulman@jct.ac.il\n1\narXiv:2511.03841v1  [cs.CR]  5 Nov 2025 1 Introduction\nThe emergence of agentic Artificial Intelligence (AI) systems, particularly\nthose powered by large language models (LLMs), has significantly trans-\nformed the landscape of software autonomy [1]. These intelligent agents, ca-\npable of reasoning, planning, delegating, and executing complex workflows,\nnow form the backbone of applications ranging from supply chain coordi-\nnation to personalized financial assistance. As the scale and complexity of\nmulti-agent ecosystems increase, so too do the requirements for secure, in-\nteroperable communication protocols.\nCommunication between autonomous agents introduces unique security\nchallenges. Unlike traditional client-server architectures, agent-based sys-\ntems must manage peer-to-peer trust, dynamic task delegation, and sensi-\ntive data sharing across heterogeneous actors. In such environments, the risk\nof credential leakage, overprivileged access, prompt injection, and unverified\nexecution grows exponentially [2, 3]. Standard security frameworks such as\nOAuth 2.0 and TLS, while foundational, do not provide sufficient granular-\nity or contextual awareness for these interactions, especially in cases where\nagents dynamically compose tasks involving payments, identity verification,\nor confidential documents [4, 5].\nTo address these gaps, several agent communication protocols have been\ndeveloped, each offering a different perspective on interoperability, trust man-\nagement, and delegation control [6]. Google’sAgent-to-Agent (A2A)protocol\n[7] introduces a declarative model for service discovery. TheAgent Commu-\nnication Protocol (ACP)[8] embraces flexibility with a registry-based model.\nTheCORAL[9] framework, in contrast, proposes a hybrid architecture inte-\ngrating on-chain smart contracts for payments with off-chain communication.\n•Google’sAgent-to-Agent (A2A)protocol [7] introduces a declarative\nmodel for service discovery.\n•TheAgent Communication Protocol (ACP)[8] embraces flexibility with\na registry-based model.\n•TheCORAL[9] framework, in contrast, proposes a hybrid architec-\nture integrating on-chain smart contracts for payments with off-chain\ncommunication.\nWhile these protocols present promising architectures, their security prop-\nerties are discussed in the literature but rarely subjected to comparative\nempirical testing [2]. This study fills this gap by providing a detailed, multi-\ndimensional security analysis and empirical testing. We establish a 14-point\n2 vulnerability taxonomy (Section 6), derived from literature and threat mod-\neling.\nOur findings reveal a critical ”architecture versus implementation” di-\nchotomy. We demonstrate that CORAL, while possessing a robust architec-\nture for integrating payments and securing data integrity via transport-layer\nvalidation, is critically vulnerable in its current public implementation due\nto fundamental authentication and authorization failures at its SSE gateway.\nConversely, our tests confirm that ACP’s architectural flexibility is, in itself,\na vulnerability, leading to predictable integrity failures and data exfiltra-\ntion in non-strict configurations. Ultimately, this paper contributes both a\ncomprehensive security taxonomy and the first empirical benchmark of these\ncompeting protocols. We conclude (Section 11) not by recommending one\nprotocol, but by proposing a hybrid model that synthesizes CORAL’s ar-\nchitectural strengths with the mandatory, granular integrity checks of ACP,\noffering a concrete path forward for resilient, AI-native communications.\n2 Background\nMulti-agent systems (MAS) leveraging artificial intelligence (AI) are increas-\ningly adopted in domains requiring distributed decision-making, automated\ncoordination, and collaborative reasoning. In such environments, autonomous\nagents often represent distinct stakeholders or functional modules, exchang-\ning structured messages through predefined interaction protocols. Repre-\nsentative use cases include autonomous orchestration, financial transaction\nsystems, healthcare diagnostics, supply chain optimization, and cybersecu-\nrity defense.\nA robust communication protocol in these contexts must ensure more\nthan reliable message delivery, it must preserve semantic integrity, context\ncontinuity, role negotiation, and, critically, security guarantees. Since AI\nagents frequently process or act upon sensitive data, vulnerabilities in their\ncommunication layers can compromise entire workflows. Therefore, secure\nagent protocols must provide protection against adversarial entities, unin-\ntended leakage, manipulation, and systemic compromise.\nBelow we summarize the principal categories of threats relevant to com-\nmunication among AI-driven agents. These categories synthesize findings\nfrom distributed systems, adversarial AI research, and classical network se-\ncurity.\n•Prompt Injection:An adversary may inject malicious instructions\ninto prompts or message payloads, coercing agents to disclose confiden-\n3 tial data or alter intended behavior. This class of attacks is extensively\ndiscussed in recent studies [10, 3].\n•Data Leakage / Exfiltration:Agents may inadvertently reveal pri-\nvate or proprietary content during multi-turn exchanges, especially\nwhen sensitive context persists across dialogue rounds [11].\n•Data Poisoning:Malicious actors can inject corrupted training or\ncontextual data, influencing downstream models to behave incorrectly\nor embed hidden triggers. Data poisoning has been empirically shown\nto scale across distributed and shared-context environments [12].\n•Adversarial / Malicious Agents:A compromised or impersonated\nagent may introduce false commands, disrupt negotiation, or propagate\nmalicious payloads across the system.\n•Replay Attacks:Attackers may capture, delay, or replay previously\nvalid messages, leading to repeated actions, synchronization errors, or\nunintended state transitions.\n•Man-in-the-Middle (MITM):Intercepting or modifying agent com-\nmunication allows attackers to compromise message integrity or confi-\ndentiality, particularly in non-aut...(truncated)"
        }
      },
      "isError": false
    }
  },
  "session_seq": 3627
}
