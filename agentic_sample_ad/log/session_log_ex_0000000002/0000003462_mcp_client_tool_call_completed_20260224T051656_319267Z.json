{
  "ts": "2026-02-24T05:16:56.319267+00:00",
  "level": "INFO",
  "component": "mcp_client",
  "action": "tool_call_completed",
  "direction": "inbound",
  "details": {
    "server_script_path": "C:\\agentic_sample_api\\agentic_sample_ad\\mcp_local\\paper_server.py",
    "tool_name": "get_paper_head",
    "result": {
      "content": [
        {
          "type": "text",
          "text": "{\n  \"ok\": true,\n  \"path\": \"C:\\\\agentic_sample_api\\\\agentic_sample_ad\\\\db\\\\paper\\\\AI Agents vs. Agentic AI_ A Conceptual taxonomy, applications and challenges.pdf\",\n  \"filename\": \"AI Agents vs. Agentic AI_ A Conceptual taxonomy, applications and challenges.pdf\",\n  \"char_count\": 16000,\n  \"head_full_char_count\": 27447,\n  \"head_max_pages\": 4,\n  \"truncated\": true,\n  \"content\": \" \\nContents lists available at ScienceDirect\\nInformation Fusion\\njournal homepage: www.elsevier.com/locate/inffus  \\nFull length article\\nAI Agents vs. Agentic AI: A Conceptual taxonomy, applications and \\nchallenges\\nRanjan Sapkota a\\n ,∗, Konstantinos I. Roumeliotis b, Manoj Karkee a\\n ,∗\\na Cornell University, Department of Biological and Environmental Engineering, Ithaca, NY, 14850, USA\\nb University of the Peloponnese, Department of Informatics and Telecommunications, Tripoli, Greece\\nA R T I C L E  I N F O\\nKeywords:\\nAI agents\\nAgentic AI\\nContext awareness\\nMulti-agent systems\\nConceptual taxonomy\\n A B S T R A C T\\nInformation fusion, in the context of the Generative AI era, must distinguish AI Agents from Agentic AI. This \\nreview critically distinguishes between AI Agents and Agentic AI, offering a structured, conceptual taxonomy, \\napplication mapping, and analysis of opportunities and challenges to clarify their divergent design philosophies \\nand capabilities. We begin by outlining the search strategy and foundational definitions, characterizing AI \\nAgents as modular systems driven and enabled by LLMs and LIMs for task-specific automation. Generative \\nAI is positioned as a precursor providing the foundation, with AI agents advancing through tool integration, \\nprompt engineering, and reasoning enhancements. We then characterize Agentic AI systems, which, in contrast \\nto AI Agents, represent a paradigm shift marked by multi-agent collaboration, dynamic task decomposition, \\npersistent memory, and coordinated autonomy. Through a chronological evaluation of architectural evolution, \\noperational mechanisms, interaction styles, and autonomy levels, we present a comparative analysis across \\nboth AI agents and agentic AI paradigms. Application domains enabled by AI Agents such as customer \\nsupport, scheduling, and data summarization are then contrasted with Agentic AI deployments in research \\nautomation, robotic coordination, and medical decision support. We further examine unique challenges in \\neach paradigm including hallucination, brittleness, emergent behavior, and coordination failure, and propose \\ntargeted solutions such as ReAct loops, retrieval-augmented generation (RAG), automation coordination layers, \\nand causal modeling. This work aims to provide a roadmap for developing robust, scalable, and explainable \\nAI-driven systems.\\n1. Introduction\\nPrior to the widespread adoption of AI Agents and Agentic AI \\n(Fig.  1) around 2022 (Before ChatGPT was introduced), the devel-\\nopment of autonomous and intelligent agents was deeply rooted in \\nfoundational paradigms of artificial intelligence, particularly multi-\\nagent systems (MAS) and expert systems, which emphasized social \\naction and distributed intelligence [1,2]. Notably, Castelfranchi [3] \\nlaid the critical groundwork by introducing ontological categories for \\nsocial action, structure, and mind, arguing that sociality emerges from \\nindividual agents’ actions and cognitive processes in a shared environ-\\nment, with concepts like goal delegation and adoption forming the basis \\nfor cooperation and organizational behavior. Similarly, Ferber [4] pro-\\nvided a comprehensive framework for MAS, defining agents as entities \\nwith autonomy, perception, and communication capabilities, and high-\\nlighting their applications in distributed problem-solving, collaborative \\nrobotics, and synthetic world simulations.\\n∗ Corresponding authors.\\nE-mail addresses: rs2672@cornell.edu (R. Sapkota), mk2684@cornell.edu (M. Karkee).\\nThese early studies established that individual social actions and \\ncognitive architectures are fundamental to modeling collective phe-\\nnomena, setting the stage for modern AI Agents. This paper builds on \\nthese foundational concepts to explore how social action modeling, as \\nproposed in [3,4], informs the design of AI Agents capable of complex, \\nsocially intelligent interactions in dynamic environments.\\nClassical Agent-like systems were designed to perform specific tasks \\nwith predefined rules, which offered limited autonomy, and minimal \\nadaptability to dynamic environments. These systems were primar-\\nily reactive or deliberative, relying on symbolic reasoning, rule-based \\nlogic, or scripted behaviors rather than the learning-driven, context-\\naware capabilities of modern AI Agents [5,6]. For instance, expert \\nsystems used knowledge bases and inference engines to emulate human \\ndecision-making in domains like medical diagnosis (e.g., MYCIN [7]). \\nOther notable examples include DENDRAL [8], an expert system for \\nmolecular structure prediction; XCON [9], used for computer system \\nhttps://doi.org/10.1016/j.inffus.2025.103599\\nReceived 29 May 2025; Received in revised form 25 July 2025; Accepted 30 July 2025\\nInformation Fusion 126 (2026) 103599 \\nAvailable online 22 August 2025 \\n1566-2535/© 2025 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license ( http://creativecommons.org/licenses/by/4.0/ ).  R. Sapkota et al.\\nconfiguration; and CLIPS [10], a rule-based production system frame-\\nwork. Systems like SOAR [11] and the subsumption architecture [12] \\nextended symbolic and reactive logic into cognitive modeling and \\nrobotics.\\nIn addition to task-specific reasoning, these agents supported lim-\\nited forms of social interaction. Early conversational systems like \\nELIZA [13] and PARRY [14] simulated basic dialogue through pattern \\nmatching and script-based responses but lacked genuine understanding \\nor contextual adaptation. Similarly, reactive agents in robotics exe-\\ncuted sense-act cycles based on fixed control rules, as seen in early \\nautonomous platforms like the Stanford Cart [15].\\nMulti-agent systems facilitated coordination among distributed en-\\ntities, exemplified by auction-based resource allocation in supply chain \\nmanagement [16–18]. Scripted AI in video games, like NPC behaviors \\nin early RPGs, used predefined decision trees [19]. Furthermore, BDI \\n(Belief-Desire-Intention) architectures enabled goal-directed behavior \\nin software agents, such as those in air traffic control simulations [20,\\n21].\\nHowever, across these diverse systems, early AI agents shared com-\\nmon limitations: they lacked self-learning, generative reasoning, and \\nadaptability to unstructured or evolving environments. These shortcom-\\nings distinguish them from Agentic AI a recent paradigm that builds on \\ndeep learning, reinforcement learning, and foundation models to enable \\nagents with contextual awareness, continuous learning, and emergent \\nautonomy [22].\\nRecent public, academic and industry interest in AI Agents and \\nAgentic AI reflects this broader transition in system capabilities. As \\nillustrated in Fig.  1, Google Trends data demonstrates a significant \\nrise in global search for both terms following the emergence of large-\\nscale generative models in late 2022. This shift is closely tied to the \\nevolution of agent design from the pre-2022 era, where AI Agents \\noperated in constrained, rule-based environments, to the post-LLM \\nperiod marked by learning-driven, flexible/adaptive architectures [23–\\n25]. These newer systems enable agents to refine their performance \\nover time and interact autonomously with unstructured, dynamic in-\\nputs [26–28]. For instance, while pre-modern expert systems required \\nmanual updates to static knowledge bases, modern agents leverage \\nemergent neural architectures to generalize across tasks [25]. The surge \\nin trend activity reflects growing awareness of this technological leap, \\nas resear...(truncated)"
        }
      ],
      "structuredContent": {
        "result": {
          "ok": true,
          "path": "C:\\agentic_sample_api\\agentic_sample_ad\\db\\paper\\AI Agents vs. Agentic AI_ A Conceptual taxonomy, applications and challenges.pdf",
          "filename": "AI Agents vs. Agentic AI_ A Conceptual taxonomy, applications and challenges.pdf",
          "char_count": 16000,
          "head_full_char_count": 27447,
          "head_max_pages": 4,
          "truncated": true,
          "content": " \nContents lists available at ScienceDirect\nInformation Fusion\njournal homepage: www.elsevier.com/locate/inffus  \nFull length article\nAI Agents vs. Agentic AI: A Conceptual taxonomy, applications and \nchallenges\nRanjan Sapkota a\n ,∗, Konstantinos I. Roumeliotis b, Manoj Karkee a\n ,∗\na Cornell University, Department of Biological and Environmental Engineering, Ithaca, NY, 14850, USA\nb University of the Peloponnese, Department of Informatics and Telecommunications, Tripoli, Greece\nA R T I C L E  I N F O\nKeywords:\nAI agents\nAgentic AI\nContext awareness\nMulti-agent systems\nConceptual taxonomy\n A B S T R A C T\nInformation fusion, in the context of the Generative AI era, must distinguish AI Agents from Agentic AI. This \nreview critically distinguishes between AI Agents and Agentic AI, offering a structured, conceptual taxonomy, \napplication mapping, and analysis of opportunities and challenges to clarify their divergent design philosophies \nand capabilities. We begin by outlining the search strategy and foundational definitions, characterizing AI \nAgents as modular systems driven and enabled by LLMs and LIMs for task-specific automation. Generative \nAI is positioned as a precursor providing the foundation, with AI agents advancing through tool integration, \nprompt engineering, and reasoning enhancements. We then characterize Agentic AI systems, which, in contrast \nto AI Agents, represent a paradigm shift marked by multi-agent collaboration, dynamic task decomposition, \npersistent memory, and coordinated autonomy. Through a chronological evaluation of architectural evolution, \noperational mechanisms, interaction styles, and autonomy levels, we present a comparative analysis across \nboth AI agents and agentic AI paradigms. Application domains enabled by AI Agents such as customer \nsupport, scheduling, and data summarization are then contrasted with Agentic AI deployments in research \nautomation, robotic coordination, and medical decision support. We further examine unique challenges in \neach paradigm including hallucination, brittleness, emergent behavior, and coordination failure, and propose \ntargeted solutions such as ReAct loops, retrieval-augmented generation (RAG), automation coordination layers, \nand causal modeling. This work aims to provide a roadmap for developing robust, scalable, and explainable \nAI-driven systems.\n1. Introduction\nPrior to the widespread adoption of AI Agents and Agentic AI \n(Fig.  1) around 2022 (Before ChatGPT was introduced), the devel-\nopment of autonomous and intelligent agents was deeply rooted in \nfoundational paradigms of artificial intelligence, particularly multi-\nagent systems (MAS) and expert systems, which emphasized social \naction and distributed intelligence [1,2]. Notably, Castelfranchi [3] \nlaid the critical groundwork by introducing ontological categories for \nsocial action, structure, and mind, arguing that sociality emerges from \nindividual agents’ actions and cognitive processes in a shared environ-\nment, with concepts like goal delegation and adoption forming the basis \nfor cooperation and organizational behavior. Similarly, Ferber [4] pro-\nvided a comprehensive framework for MAS, defining agents as entities \nwith autonomy, perception, and communication capabilities, and high-\nlighting their applications in distributed problem-solving, collaborative \nrobotics, and synthetic world simulations.\n∗ Corresponding authors.\nE-mail addresses: rs2672@cornell.edu (R. Sapkota), mk2684@cornell.edu (M. Karkee).\nThese early studies established that individual social actions and \ncognitive architectures are fundamental to modeling collective phe-\nnomena, setting the stage for modern AI Agents. This paper builds on \nthese foundational concepts to explore how social action modeling, as \nproposed in [3,4], informs the design of AI Agents capable of complex, \nsocially intelligent interactions in dynamic environments.\nClassical Agent-like systems were designed to perform specific tasks \nwith predefined rules, which offered limited autonomy, and minimal \nadaptability to dynamic environments. These systems were primar-\nily reactive or deliberative, relying on symbolic reasoning, rule-based \nlogic, or scripted behaviors rather than the learning-driven, context-\naware capabilities of modern AI Agents [5,6]. For instance, expert \nsystems used knowledge bases and inference engines to emulate human \ndecision-making in domains like medical diagnosis (e.g., MYCIN [7]). \nOther notable examples include DENDRAL [8], an expert system for \nmolecular structure prediction; XCON [9], used for computer system \nhttps://doi.org/10.1016/j.inffus.2025.103599\nReceived 29 May 2025; Received in revised form 25 July 2025; Accepted 30 July 2025\nInformation Fusion 126 (2026) 103599 \nAvailable online 22 August 2025 \n1566-2535/© 2025 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license ( http://creativecommons.org/licenses/by/4.0/ ).  R. Sapkota et al.\nconfiguration; and CLIPS [10], a rule-based production system frame-\nwork. Systems like SOAR [11] and the subsumption architecture [12] \nextended symbolic and reactive logic into cognitive modeling and \nrobotics.\nIn addition to task-specific reasoning, these agents supported lim-\nited forms of social interaction. Early conversational systems like \nELIZA [13] and PARRY [14] simulated basic dialogue through pattern \nmatching and script-based responses but lacked genuine understanding \nor contextual adaptation. Similarly, reactive agents in robotics exe-\ncuted sense-act cycles based on fixed control rules, as seen in early \nautonomous platforms like the Stanford Cart [15].\nMulti-agent systems facilitated coordination among distributed en-\ntities, exemplified by auction-based resource allocation in supply chain \nmanagement [16–18]. Scripted AI in video games, like NPC behaviors \nin early RPGs, used predefined decision trees [19]. Furthermore, BDI \n(Belief-Desire-Intention) architectures enabled goal-directed behavior \nin software agents, such as those in air traffic control simulations [20,\n21].\nHowever, across these diverse systems, early AI agents shared com-\nmon limitations: they lacked self-learning, generative reasoning, and \nadaptability to unstructured or evolving environments. These shortcom-\nings distinguish them from Agentic AI a recent paradigm that builds on \ndeep learning, reinforcement learning, and foundation models to enable \nagents with contextual awareness, continuous learning, and emergent \nautonomy [22].\nRecent public, academic and industry interest in AI Agents and \nAgentic AI reflects this broader transition in system capabilities. As \nillustrated in Fig.  1, Google Trends data demonstrates a significant \nrise in global search for both terms following the emergence of large-\nscale generative models in late 2022. This shift is closely tied to the \nevolution of agent design from the pre-2022 era, where AI Agents \noperated in constrained, rule-based environments, to the post-LLM \nperiod marked by learning-driven, flexible/adaptive architectures [23–\n25]. These newer systems enable agents to refine their performance \nover time and interact autonomously with unstructured, dynamic in-\nputs [26–28]. For instance, while pre-modern expert systems required \nmanual updates to static knowledge bases, modern agents leverage \nemergent neural architectures to generalize across tasks [25]. The surge \nin trend activity reflects growing awareness of this technological leap, \nas researchers and practitioners seek tools that go beyond automation \ntoward autonomy and general-purpose reasoning. Moreover, applica-\ntions are no longer confined to narrow domains like simulations or \nlogistics, but now extend to broad practical settings demanding real-\ntime reasoning and adaptive control. This momentum, as visualized in \nFig.  1, highlights the significance of recent architectural advances in \nscaling autonomous agents for real-world deployment.\nThe release of ChatGPT in No...(truncated)"
        }
      },
      "isError": false
    }
  },
  "session_seq": 3462
}
